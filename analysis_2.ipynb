{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# short_test.ipynb\n",
    "Functions to examine rolling correlations between device sensor outputs.\n",
    "Author: – Jon Clucas, 2017 jon.clucas@childmind.org\n",
    "© 2017, Child Mind Institute, Apache v2.0 License\n",
    "\n",
    "setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from annotate_range import annotation_line\n",
    "from astropy.stats import median_absolute_deviation as mad\n",
    "from chart_data import write_csv\n",
    "from config import short_dir, cache_hashes, test_urls\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib.dates import DateFormatter\n",
    "from normalize_acc_data import actigraph_acc, geneactiv_acc\n",
    "from plot_normalized_vector_lengths import baseshift_and_renormalize\n",
    "from utilities.fetch_data import fetch_check_data, fetch_data, fetch_hash\n",
    "import json, numpy as np, os, pandas as pd, matplotlib.pyplot as plt\n",
    "with open(os.path.join('./line_charts/device_colors.json')) as fp:\n",
    "    color_key = json.load(fp)\n",
    "pd.set_option('mode.use_inf_as_null', True)\n",
    "hashes = cache_hashes()\n",
    "if not os.path.exists('./sample_data'):\n",
    "    os.makedirs('./sample_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_hashes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ppg in ['e4_ppg', 'Wavelet_ppg']:\n",
    "    try:\n",
    "        fetch_check_data(ppg, test_urls()[ppg], hashes, cache_directory='./sample_data', append='.csv', verbose=True)\n",
    "    except OSError:\n",
    "        hashes[ppg] = fetch_hash(fetch_data(test_urls()[ppg], os.path.join('./sample_data', ppg), '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
    "    data1     = np.asarray(data1)\n",
    "    data2     = np.asarray(data2)\n",
    "    mean      = np.mean([data1, data2], axis=0)\n",
    "    diff      = data1 - data2                   # Difference between data1 and data2\n",
    "    md        = np.mean(diff)                   # Mean of the difference\n",
    "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
    "\n",
    "    plt.scatter(mean, diff, *args, **kwargs)\n",
    "    plt.axhline(md,           color='gray', linestyle='--')\n",
    "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
    "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
    "\n",
    "def df_devices(devices, sensor, start, stop):\n",
    "    \"\"\"\n",
    "    Function to calculate rolling correlations between two sensor data streams.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    devices : list of (subdirectory, device) tuples (len 2)\n",
    "        each string is the name of one of the two devices to compare\n",
    "        \n",
    "    sensor : string\n",
    "        the sensor to compare\n",
    "        \n",
    "    start : datetime\n",
    "        beginning of time to compare\n",
    "        \n",
    "    stop : datetime\n",
    "        end of time to compare\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "        merged dataframe with a column per device\n",
    "    \"\"\"\n",
    "    suffix = '.csv'\n",
    "    s = []\n",
    "    for i, device in enumerate(devices):\n",
    "        acc_sub = '_'.join([device[0], 'acc', 'quicktest'])\n",
    "        if not acc_sub in acc_hashes:\n",
    "            try:\n",
    "                fetch_check_data(acc_sub, test_urls()[acc_sub], acc_hashes, cache_directory='./sample_data',\n",
    "                                 append='.csv', verbose=True)\n",
    "            except OSError:\n",
    "                acc_hashes[acc_sub] = fetch_data(test_urls()[acc_sub], os.path.join('./sample_data', acc_sub), '.csv')\n",
    "        s.append(pd.read_csv(os.path.join('./sample_data', ''.join([acc_sub, suffix])),\n",
    "                 usecols=['Timestamp', 'normalized_vector_length'],\n",
    "                 parse_dates=['Timestamp'], infer_datetime_format=True))\n",
    "        s[i] = s[i].loc[(s[i]['Timestamp'] >= start) & (s[i]['Timestamp'] <= stop)].copy()\n",
    "        s[i] = baseshift_and_renormalize(s[i])\n",
    "        if device[1] == 'ActiGraph':\n",
    "            s[i][['Timestamp']] = s[i].Timestamp.apply(lambda x: x - timedelta(microseconds\n",
    "                        =1000))\n",
    "        s[i].set_index('Timestamp', inplace=True)\n",
    "    df = s[0].merge(s[1], left_index=True, right_index=True, suffixes=(''.join([\n",
    "         '_', devices[0][1]]), ''.join(['_', devices[1][1]])))\n",
    "    for i in range(2, len(s), 1):\n",
    "        df = df.merge(s[i], left_index=True, right_index=True, suffixes=('', ''.join(['_', devices[i][1]])))\n",
    "    return(df)\n",
    "    \n",
    "def linechart(df, plot_label, line=True, full=False):\n",
    "    \"\"\"\n",
    "    Function to build a linechart and export a PNG and an SVG of the image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        dataframe to plot\n",
    "        \n",
    "    plot_label : string\n",
    "        plot title\n",
    "        \n",
    "    line : boolean\n",
    "        True for lineplot, False for scatterplot\n",
    "        \n",
    "    full : boolean\n",
    "        True for ylim=[0, 1], False for ylim=[0, 3×max(mad)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    plotted : boolean\n",
    "        True if data plotted, False otherwise\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    inline plot\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = min(df.index.values)\n",
    "    except:\n",
    "        print(\"End of data.\")\n",
    "        return False\n",
    "    stop = max(df.index.values)\n",
    "    print(\"Plotting...\")\n",
    "    print(plot_label)\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=75)\n",
    "    plt.rcParams['agg.path.chunksize'] = 10000\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_ylabel('unit cube normalized vector length')\n",
    "    annotations_a = {}\n",
    "    annotations_b = {}\n",
    "    annotation_y = 0.04\n",
    "    mad_values = []\n",
    "    for device in list(df.columns):\n",
    "        if device.startswith('normalized'):\n",
    "            d2 = device[25:]\n",
    "        else:\n",
    "            d2 = device\n",
    "        plot_line = df[[device]].dropna()\n",
    "        mp = mad(plot_line)\n",
    "        if mp > 0:\n",
    "            print(mp)\n",
    "            mad_values.append(mp)\n",
    "        else:\n",
    "            mp = plot_line.std()[0]\n",
    "            if mp > 0:\n",
    "                print(mp)\n",
    "                mad_values.append(mp)\n",
    "            else:\n",
    "                print(max(plot_line[[device]]))\n",
    "                mad_values.append(max(plot_line[[device]]))\n",
    "        if \"GENEActiv\" in device:\n",
    "            label = \"GENEActiv\"\n",
    "        elif device == \"Actigraph\":\n",
    "            label = \"ActiGraph\"\n",
    "        else:\n",
    "            label = d2\n",
    "        \"\"\"\n",
    "        if device == \"Wavelet\":\n",
    "            ax.plot_date(x=plot_line.index, y=plot_line, color=color_key[\n",
    "                         device], alpha=0.5, label=label, marker=\"o\",\n",
    "                         linestyle=\"None\")\n",
    "        else:\n",
    "        \"\"\"\n",
    "        if line:\n",
    "            ax.plot_date(x=plot_line.index, y=plot_line, alpha=0.5, label=label, marker=\"\", linestyle=\n",
    "                             \"solid\")\n",
    "        else:\n",
    "            ax.plot_date(x=plot_line.index, y=plot_line, alpha=0.5, label=label, marker=\"o\", linestyle=\n",
    "                             \"None\")\n",
    "        ax.legend(loc='best', fancybox=True, framealpha=0.5)\n",
    "    try:\n",
    "        ylim = max(mad_values)\n",
    "    except:\n",
    "        ylim = 0\n",
    "    if full or ylim == 0:\n",
    "        ax.set_ylim([0, 1])\n",
    "    else:\n",
    "        try:\n",
    "            ax.set_ylim([0, 3 * ylim])\n",
    "        except:\n",
    "            ax.set_ylim([0, 1])\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%H:%M:%S'))\n",
    "    plt.suptitle(plot_label)\n",
    "    plt.xticks(rotation=65)\n",
    "    plt.show()\n",
    "    return True\n",
    "    \n",
    "def rolling_window(a, window):\n",
    "    # http://wichita.ogs.ou.edu/documents/python/xcor.py\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "    \n",
    "def xcorr(x,y):\n",
    "  \"\"\"c=xcor(x,y)\n",
    "  Fast implementation to compute the normalized cross correlation where x and y are 1D numpy arrays\n",
    "  x is the timeseries\n",
    "  y is the template time series\n",
    "  returns a numpy 1D array of correlation coefficients, c\"\n",
    "  \n",
    "  The standard deviation algorithm in numpy is the biggest slow down in this method.  \n",
    "  The issue has been identified hopefully they make improvements.\n",
    "\n",
    "  http://wichita.ogs.ou.edu/documents/python/xcor.py\n",
    "  \"\"\"\n",
    "  N=len(x)\n",
    "  M=len(y)\n",
    "  meany=np.mean(y)\n",
    "  stdy=np.std(np.asarray(y))\n",
    "  tmp=rolling_window(x,M)\n",
    "  c=np.sum((y-meany)*(tmp-np.reshape(np.mean(tmp,-1),(N-M+1,1))),-1)/(M*np.std(tmp,-1)*stdy)\n",
    "\n",
    "  return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a1 = actigraph_acc(os.path.join(short_dir, 'A'), os.path.join(short_dir, 'A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = geneactiv_acc(os.path.join(short_dir, 'G1'), os.path.join(short_dir, 'G1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2 = geneactiv_acc(os.path.join(short_dir, 'G2'), os.path.join(short_dir, 'G2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_devices([('A', 'ActiGraph'), ('G1', 'GENEActiv'), ('G2', 'GENEActiv')], 'accelerometer',\n",
    "     datetime(2017, 4, 28, 15, 30), datetime(2017, 4, 28, 15, 48))\n",
    "df.rename(columns={'normalized_vector_length': 'normalized_vector_length_GENEActiv(2)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linechart(df, 'ActiGraph vs 2×GENEActiv', line=True, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linechart(df, 'ActiGraph vs 2×GENEActiv', line=False, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Avalues = df['normalized_vector_length_ActiGraph'].values\n",
    "G1values = df['normalized_vector_length_GENEActiv'].values\n",
    "G2values = df['normalized_vector_length_GENEActiv(2)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shiftG1G2 = len(G1values) - np.argmax(np.correlate(G1values, G2values, mode='full'))\n",
    "shiftG1A = len(G1values) - np.argmax(np.correlate(G1values, Avalues, mode='full'))\n",
    "shiftG2A = len(G2values) - np.argmax(np.correlate(G2values, Avalues, mode='full'))\n",
    "shiftGA = np.int(np.mean([shiftG1A, shiftG2A]))\n",
    "[shiftG1G2, shiftG1A, shiftG2A, shiftGA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift_GA = np.abs(shiftGA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Avalues_shifted = Avalues[:G1values.shape[0]-shift_GA]\n",
    "G1values_shifted = G1values[shift_GA:G1values.shape[0]]\n",
    "G2values_shifted = G2values[shift_GA:G2values.shape[0]]\n",
    "[np.shape(G1values_shifted), np.shape(G2values_shifted), np.shape(Avalues_shifted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[xcorr(G1values_shifted, G2values_shifted), xcorr(Avalues_shifted, G1values_shifted), xcorr(Avalues_shifted, G2values_shifted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shifted_t = [datetime(2017, 4, 28, 15, 30)]\n",
    "while len(shifted_t) < np.shape(Avalues_shifted)[0]:\n",
    "    shifted_t.append(shifted_t[-1] + timedelta(seconds=0.0166))\n",
    "shifted_df = pd.DataFrame({'normalized_vector_length_ActiGraph': Avalues_shifted,\n",
    "            'normalized_vector_length_GENEActiv': G1values_shifted,\n",
    "            'normalized_vector_length_GENEActiv(2)': G2values_shifted, 'Timestamp':shifted_t})\n",
    "shifted_df.set_index('Timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = shifted_t[0]\n",
    "stop = shifted_t[-1]\n",
    "while start < stop:\n",
    "    new_start = start + timedelta(seconds=180)\n",
    "    plot_df = shifted_df.loc[(shifted_df.index >= start) & (shifted_df.index <= new_start)].copy()\n",
    "    label = '–'.join([start.strftime('%H:%M:%S'), new_start.strftime('%H:%M:%S')])\n",
    "    linechart(plot_df, label, False)\n",
    "    print(xcorr(plot_df['normalized_vector_length_GENEActiv'].values,\n",
    "                plot_df['normalized_vector_length_GENEActiv(2)'].values))\n",
    "    print(xcorr(plot_df['normalized_vector_length_ActiGraph'].values,\n",
    "                plot_df['normalized_vector_length_GENEActiv'].values))\n",
    "    print(xcorr(plot_df['normalized_vector_length_ActiGraph'].values,\n",
    "                plot_df['normalized_vector_length_GENEActiv(2)'].values))\n",
    "    start = new_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linechart(shifted_df, 'ActiGraph vs 2×GENEActiv, shifted', line=False, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linechart(shifted_df, 'ActiGraph vs 2×GENEActiv, shifted', line=True, full=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cut middle portion out when devices were being transferred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start1 = datetime(2017,4,28,15,30)\n",
    "stop1 = datetime(2017,4,28,15,37)\n",
    "start2 = datetime(2017,4,28,15,40)\n",
    "stop2 = datetime(2017,4,28,15,48)\n",
    "cropped_df = shifted_df.loc[(shifted_df.index >= start1) & (shifted_df.index <= stop1) |\n",
    "                            (shifted_df.index >= start2) & (shifted_df.index <= stop2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linechart(cropped_df, 'ActiGraph vs 2×GENEActiv, shifted, cropped section', line=True, full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Avalues_cropped = cropped_df['normalized_vector_length_ActiGraph'].values\n",
    "G1values_cropped = cropped_df['normalized_vector_length_GENEActiv'].values\n",
    "G2values_cropped = cropped_df['normalized_vector_length_GENEActiv(2)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute normalized cross-correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[xcorr(G1values_cropped, G2values_cropped), xcorr(Avalues_cropped, G1values_cropped),\n",
    " xcorr(Avalues_cropped, G2values_cropped)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot x-second windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = datetime(2017,4,28,15,30) #shifted_t[0]\n",
    "stop = datetime(2017,4,28,15,48) #shifted_t[-1]\n",
    "plot_data = True\n",
    "while start < stop and plot_data:\n",
    "    new_start = start + timedelta(seconds=10)\n",
    "    plot_df = cropped_df.loc[(cropped_df.index >= start) & (cropped_df.index <= new_start)].copy()\n",
    "    label = '–'.join([start.strftime('%H:%M:%S'), new_start.strftime('%H:%M:%S')])\n",
    "    plot_data = linechart(plot_df, label, line=True, full=False)\n",
    "    #print(xcorr(plot_df['normalized_vector_length_GENEActiv'].values,\n",
    "    #            plot_df['normalized_vector_length_GENEActiv(2)'].values))\n",
    "    #print(xcorr(plot_df['normalized_vector_length_ActiGraph'].values,\n",
    "    #            plot_df['normalized_vector_length_GENEActiv'].values))\n",
    "    #print(xcorr(plot_df['normalized_vector_length_ActiGraph'].values,\n",
    "    #            plot_df['normalized_vector_length_GENEActiv(2)'].values))\n",
    "    start = new_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.shape(G1values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = datetime(2017, 4, 28, 15, 29)\n",
    "stop = datetime(2017, 4, 28, 16, 29)\n",
    "while start < stop:\n",
    "    new_start = start + timedelta(seconds=30)\n",
    "    plot_df = df.loc[(df.index >= start) & (df.index <= new_start)].copy()\n",
    "    label = '–'.join([start.strftime('%H:%M:%S'), new_start.strftime('%H:%M:%S')])\n",
    "    linechart(plot_df, label, False)\n",
    "    start = new_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = datetime(2017, 4, 28, 15, 29)\n",
    "stop = datetime(2017, 4, 28, 16, 29)\n",
    "while start < stop:\n",
    "    new_start = start + timedelta(seconds=30)\n",
    "    plot_df = df.loc[(df.index >= start) & (df.index <= new_start)].copy()\n",
    "    label = '–'.join([start.strftime('%H:%M:%S'), new_start.strftime('%H:%M:%S')])\n",
    "    linechart(plot_df, label, False, True)\n",
    "    start = new_start"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
